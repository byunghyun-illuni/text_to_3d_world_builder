"""
Text â†’ Image â†’ 3D Pipeline
í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ë°›ì•„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , 3D ëª¨ë¸ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´í”„ë¼ì¸

ì‚¬ìš©ë²•:
    python text_to_3d_pipeline.py "A cute cartoon robot toy"
    python text_to_3d_pipeline.py --prompt "A medieval sword" --output sword.glb
"""

import os
os.environ['OPENCV_IO_ENABLE_OPENEXR'] = '1'
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import argparse
import io
from PIL import Image
import torch
from typing import Optional
from pathlib import Path

# ============================================================================
# Configuration
# ============================================================================

# Gemini API í‚¤ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì„¤ì •)
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ (ModelScopeì—ì„œ ë‹¤ìš´ë¡œë“œëœ ê²½ë¡œ)
DINOV3_LOCAL_PATH = "/home/byunghyun/.cache/modelscope/facebook/dinov3-vitl16-pretrain-lvd1689m"
RMBG_LOCAL_PATH = "/home/byunghyun/.cache/modelscope/briaai/RMBG-2.0"

# 3D ìƒì„±ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
PROMPT_TEMPLATE_3D = """Generate an image of: {description}

Style requirements:
- 3D rendered style, high quality
- Single object, centered in frame
- Pure white or transparent background
- Studio lighting with soft shadows
- Front view or 3/4 view angle
- Full object visible, not cropped
- Clean isolated object for 3D conversion"""


# ============================================================================
# Text-to-Image Module (Gemini/Imagen)
# ============================================================================

class TextToImageGenerator:
    """Gemini/Imagen APIë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ê¸°"""

    def __init__(self, api_key: str):
        from google import genai
        from google.genai import types
        self.genai = genai
        self.types = types
        self.client = genai.Client(api_key=api_key)

    def generate(self, prompt: str, output_path: str = "generated_image.png") -> Optional[Image.Image]:
        """
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            prompt: ìƒì„±í•  ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…
            output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

        Returns:
            ìƒì„±ëœ PIL Image ê°ì²´, ì‹¤íŒ¨ ì‹œ None
        """
        # 3D ë³€í™˜ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        full_prompt = PROMPT_TEMPLATE_3D.format(description=prompt)

        # ì—¬ëŸ¬ ëª¨ë¸ ìˆœì°¨ ì‹œë„
        models = [
            ("gemini-2.0-flash-exp-image-generation", self._generate_gemini),
            ("gemini-2.5-flash-image", self._generate_gemini),
            ("imagen-4.0-generate-001", self._generate_imagen),
        ]

        for model_name, generator_fn in models:
            print(f"Trying {model_name}...")
            try:
                image = generator_fn(model_name, full_prompt)
                if image:
                    image.save(output_path)
                    print(f"Image saved to: {output_path}")
                    return image
            except Exception as e:
                print(f"{model_name} failed: {e}")
                continue

        return None

    def _generate_gemini(self, model: str, prompt: str) -> Optional[Image.Image]:
        """Gemini ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±"""
        response = self.client.models.generate_content(
            model=model,
            contents=prompt,
            config=self.types.GenerateContentConfig(
                response_modalities=["IMAGE", "TEXT"],
            )
        )

        for part in response.candidates[0].content.parts:
            if part.inline_data is not None:
                image_data = part.inline_data.data
                return Image.open(io.BytesIO(image_data))

        return None

    def _generate_imagen(self, model: str, prompt: str) -> Optional[Image.Image]:
        """Imagen ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±"""
        response = self.client.models.generate_images(
            model=model,
            prompt=prompt,
            config=self.types.GenerateImagesConfig(
                number_of_images=1,
                aspect_ratio="1:1",
            )
        )

        if response.generated_images:
            image_bytes = response.generated_images[0].image.image_bytes
            return Image.open(io.BytesIO(image_bytes))

        return None


# ============================================================================
# Image-to-3D Module (TRELLIS.2)
# ============================================================================

class ImageTo3DGenerator:
    """TRELLIS.2ë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€-3D ìƒì„±ê¸°"""

    def __init__(self):
        self.pipeline = None
        self._patch_models()

    def _patch_models(self):
        """ë¡œì»¬ ëª¨ë¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ë„ë¡ íŒ¨ì¹˜"""
        # DinoV3 íŒ¨ì¹˜
        from trellis2.modules import image_feature_extractor
        OriginalDinoV3 = image_feature_extractor.DinoV3FeatureExtractor

        class PatchedDinoV3(OriginalDinoV3):
            def __init__(self, model_name: str, image_size=512):
                if "dinov3-vitl16" in model_name:
                    model_name = DINOV3_LOCAL_PATH
                super().__init__(model_name, image_size)

        image_feature_extractor.DinoV3FeatureExtractor = PatchedDinoV3

        # BiRefNet íŒ¨ì¹˜
        from trellis2.pipelines import rembg as rembg_module
        OriginalBiRefNet = rembg_module.BiRefNet

        class PatchedBiRefNet(OriginalBiRefNet):
            def __init__(self, model_name: str):
                if "RMBG-2.0" in model_name:
                    model_name = RMBG_LOCAL_PATH
                super().__init__(model_name)

        rembg_module.BiRefNet = PatchedBiRefNet

    def load_pipeline(self):
        """TRELLIS.2 íŒŒì´í”„ë¼ì¸ ë¡œë“œ"""
        if self.pipeline is None:
            print("Loading TRELLIS.2 pipeline...")
            from trellis2.pipelines import Trellis2ImageTo3DPipeline
            self.pipeline = Trellis2ImageTo3DPipeline.from_pretrained("microsoft/TRELLIS.2-4B")
            self.pipeline.cuda()
            print("Pipeline loaded successfully")

    def generate(
        self,
        image: Image.Image,
        output_path: str = "output.glb",
        decimation_target: int = 100000,
        texture_size: int = 2048,
    ) -> str:
        """
        ì´ë¯¸ì§€ë¥¼ 3D ëª¨ë¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            image: ì…ë ¥ PIL Image
            output_path: ì¶œë ¥ GLB íŒŒì¼ ê²½ë¡œ
            decimation_target: ë©”ì‹œ ë‹¨ìˆœí™” ëª©í‘œ ë©´ ìˆ˜
            texture_size: í…ìŠ¤ì²˜ í•´ìƒë„

        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        import o_voxel

        self.load_pipeline()

        print(f"Generating 3D mesh from image ({image.size})...")
        mesh = self.pipeline.run(image)[0]

        print(f"Mesh generated: {mesh.vertices.shape[0]} vertices, {mesh.faces.shape[0]} faces")

        # ë©”ì‹œ ë‹¨ìˆœí™”
        mesh.simplify(1000000)

        # GLB ë‚´ë³´ë‚´ê¸°
        print("Exporting to GLB...")
        glb = o_voxel.postprocess.to_glb(
            vertices=mesh.vertices,
            faces=mesh.faces,
            attr_volume=mesh.attrs,
            coords=mesh.coords,
            attr_layout=mesh.layout,
            voxel_size=mesh.voxel_size,
            aabb=[[-0.5, -0.5, -0.5], [0.5, 0.5, 0.5]],
            decimation_target=decimation_target,
            texture_size=texture_size,
            remesh=True,
        )
        glb.export(output_path, extension_webp=True)

        print(f"3D model saved to: {output_path}")
        print(f"GPU Memory used: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB")

        return output_path


# ============================================================================
# Full Pipeline
# ============================================================================

class TextTo3DPipeline:
    """Text â†’ Image â†’ 3D ì „ì²´ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, api_key: str = GEMINI_API_KEY):
        self.text_to_image = TextToImageGenerator(api_key)
        self.image_to_3d = ImageTo3DGenerator()

    def generate(
        self,
        text_prompt: str,
        output_path: str = "output.glb",
        keep_image: bool = True,
    ) -> dict:
        """
        í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ë°›ì•„ 3D ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            text_prompt: ìƒì„±í•  3D ëª¨ë¸ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…
            output_path: ì¶œë ¥ GLB íŒŒì¼ ê²½ë¡œ
            keep_image: ì¤‘ê°„ ì´ë¯¸ì§€ íŒŒì¼ ë³´ì¡´ ì—¬ë¶€

        Returns:
            ê²°ê³¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            "success": False,
            "prompt": text_prompt,
            "image_path": None,
            "model_path": None,
            "error": None,
        }

        # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
        output_stem = Path(output_path).stem
        image_path = f"{output_stem}_image.png"

        # Step 1: Text â†’ Image
        print("\n" + "=" * 60)
        print("Step 1: Text â†’ Image (Gemini/Imagen)")
        print("=" * 60)
        print(f"Prompt: {text_prompt}")

        image = self.text_to_image.generate(text_prompt, image_path)

        if image is None:
            result["error"] = "Image generation failed"
            print(f"\nâŒ {result['error']}")
            return result

        result["image_path"] = image_path
        print(f"âœ… Image generated: {image_path}")

        # Step 2: Image â†’ 3D
        print("\n" + "=" * 60)
        print("Step 2: Image â†’ 3D (TRELLIS.2)")
        print("=" * 60)

        try:
            model_path = self.image_to_3d.generate(image, output_path)
            result["model_path"] = model_path
            result["success"] = True
            print(f"âœ… 3D model generated: {model_path}")
        except Exception as e:
            result["error"] = f"3D generation failed: {e}"
            print(f"\nâŒ {result['error']}")
            return result

        # ì¤‘ê°„ ì´ë¯¸ì§€ ì‚­ì œ (ì˜µì…˜)
        if not keep_image and result["image_path"]:
            os.remove(result["image_path"])
            result["image_path"] = None

        print("\n" + "=" * 60)
        print("âœ… Pipeline completed successfully!")
        print("=" * 60)

        return result

    def generate_from_image(
        self,
        image_path: str,
        output_path: str = "output.glb",
    ) -> dict:
        """
        ê¸°ì¡´ ì´ë¯¸ì§€ì—ì„œ 3D ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            output_path: ì¶œë ¥ GLB íŒŒì¼ ê²½ë¡œ

        Returns:
            ê²°ê³¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            "success": False,
            "image_path": image_path,
            "model_path": None,
            "error": None,
        }

        print("\n" + "=" * 60)
        print("Image â†’ 3D (TRELLIS.2)")
        print("=" * 60)

        try:
            image = Image.open(image_path)
            print(f"Input image: {image_path} ({image.size})")

            model_path = self.image_to_3d.generate(image, output_path)
            result["model_path"] = model_path
            result["success"] = True
            print(f"âœ… 3D model generated: {model_path}")
        except Exception as e:
            result["error"] = f"3D generation failed: {e}"
            print(f"\nâŒ {result['error']}")

        return result


# ============================================================================
# CLI Interface
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Text â†’ Image â†’ 3D Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # í…ìŠ¤íŠ¸ì—ì„œ 3D ëª¨ë¸ ìƒì„±
  python text_to_3d_pipeline.py "A cute cartoon robot"

  # íŠ¹ì • ì¶œë ¥ íŒŒì¼ëª… ì§€ì •
  python text_to_3d_pipeline.py --prompt "A medieval sword" --output sword.glb

  # ê¸°ì¡´ ì´ë¯¸ì§€ì—ì„œ 3D ëª¨ë¸ ìƒì„±
  python text_to_3d_pipeline.py --image input.png --output model.glb
        """
    )

    parser.add_argument(
        "prompt",
        nargs="?",
        help="ìƒì„±í•  3D ëª¨ë¸ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…"
    )
    parser.add_argument(
        "--prompt", "-p",
        dest="prompt_arg",
        help="ìƒì„±í•  3D ëª¨ë¸ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª… (ëŒ€ì•ˆ)"
    )
    parser.add_argument(
        "--image", "-i",
        help="ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ (ì´ë¯¸ì§€ì—ì„œ 3D ìƒì„± ì‹œ)"
    )
    parser.add_argument(
        "--output", "-o",
        default="output.glb",
        help="ì¶œë ¥ GLB íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: output.glb)"
    )
    parser.add_argument(
        "--api-key",
        default=GEMINI_API_KEY,
        help="Gemini API í‚¤"
    )
    parser.add_argument(
        "--keep-image",
        action="store_true",
        help="ì¤‘ê°„ ìƒì„± ì´ë¯¸ì§€ ë³´ì¡´"
    )

    args = parser.parse_args()

    # í”„ë¡¬í”„íŠ¸ ê²°ì •
    prompt = args.prompt or args.prompt_arg

    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = TextTo3DPipeline(api_key=args.api_key)

    if args.image:
        # ì´ë¯¸ì§€ì—ì„œ 3D ìƒì„±
        result = pipeline.generate_from_image(args.image, args.output)
    elif prompt:
        # í…ìŠ¤íŠ¸ì—ì„œ 3D ìƒì„±
        result = pipeline.generate(prompt, args.output, args.keep_image)
    else:
        parser.print_help()
        return

    # ê²°ê³¼ ì¶œë ¥
    if result["success"]:
        print(f"\nğŸ‰ Success! Output: {result['model_path']}")
    else:
        print(f"\nğŸ’¥ Failed: {result['error']}")
        exit(1)


if __name__ == "__main__":
    main()
